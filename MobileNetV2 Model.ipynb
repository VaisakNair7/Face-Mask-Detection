{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f147eb",
   "metadata": {},
   "source": [
    "## Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8942aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout, Flatten, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb4c03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 is to hide gpu device. Remove this value to use Tensorflow GPU if you have CUDA installed.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c7a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define epochs and batch size\n",
    "epochs = 20\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9142dff2",
   "metadata": {},
   "source": [
    "## Preparing train and test set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d5af1",
   "metadata": {},
   "source": [
    "#### ImageDataGenerator is used for data augmentation. Data augmentation is a technique to artificially create new training data from existing training data.\n",
    "#### This will improve accuracy and add more training data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d5db42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce67630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3392 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('dataset/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = bs,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d9dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "948e7d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 441 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('dataset/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = bs,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91292f22",
   "metadata": {},
   "source": [
    "## Load and build the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d5b41c",
   "metadata": {},
   "source": [
    "#### MobileNetV2 is a lightweight Keras application with less no of parameters and depth.  It takes an input size of (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b233b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "mobilenet = MobileNetV2(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14538f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to use the imagenet weights and add few layers on top of the MobileNetV2.\n",
    "for layer in mobilenet.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b57d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = mobilenet.output\n",
    "headModel = MaxPooling2D(pool_size = (7, 7))(headModel)\n",
    "headModel = Flatten()(headModel)\n",
    "headModel = Dense(128, activation = \"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation = \"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76540dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = mobilenet.input, outputs = headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a425c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate = 1e-3, decay = 1e-3 // epochs)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f853da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This callback will save the model which has the best accuracy in epoch, as 'MobileNetV2.h5'\n",
    "checkpoint = ModelCheckpoint('MobileNetV2.h5', monitor = 'accuracy', save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcf8b2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 7s 1s/step - loss: 2.8577 - accuracy: 0.6146\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.8757 - accuracy: 0.6354\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 4s 964ms/step - loss: 0.5544 - accuracy: 0.8646\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 3s 935ms/step - loss: 0.6765 - accuracy: 0.8333\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 4s 924ms/step - loss: 0.4635 - accuracy: 0.8333\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 4s 941ms/step - loss: 0.4340 - accuracy: 0.8854\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 3s 913ms/step - loss: 0.4053 - accuracy: 0.9062\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 3s 908ms/step - loss: 0.2171 - accuracy: 0.9167\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 3s 942ms/step - loss: 0.2272 - accuracy: 0.9167\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 4s 949ms/step - loss: 0.1406 - accuracy: 0.9479\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 3s 957ms/step - loss: 0.2214 - accuracy: 0.8854\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 4s 991ms/step - loss: 0.0812 - accuracy: 0.9896\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 3s 953ms/step - loss: 0.0971 - accuracy: 0.9479\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 4s 974ms/step - loss: 0.1459 - accuracy: 0.9375\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 4s 919ms/step - loss: 0.1240 - accuracy: 0.9479\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 4s 969ms/step - loss: 0.1793 - accuracy: 0.9375\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 4s 982ms/step - loss: 0.1282 - accuracy: 0.9583\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 4s 940ms/step - loss: 0.1582 - accuracy: 0.9479\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 4s 966ms/step - loss: 0.1649 - accuracy: 0.9375\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 4s 951ms/step - loss: 0.0815 - accuracy: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13cc168b850>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  training_set,\n",
    "  validation_data = test_set,\n",
    "  epochs = epochs,\n",
    "  steps_per_epoch = len(training_set) // bs,\n",
    "  validation_steps = len(test_set) // bs,\n",
    "  workers = 4,\n",
    "  callbacks = checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bded151",
   "metadata": {},
   "source": [
    "## Now Let's test the model with a image from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d7149c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/test/with_mask/253.jpg', target_size = (224, 224))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "test_image = preprocess_input(test_image)\n",
    "result = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c46982a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with_mask': 0, 'without_mask': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac2f4a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Mask\n"
     ]
    }
   ],
   "source": [
    "if np.argmax(result[0]) == 0:\n",
    "  print('With Mask')\n",
    "else:\n",
    "  print('Without Mask')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
